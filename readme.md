# Dog Fight MCP (Multi-Perspective Co-creation)

## Introduction

Dog Fight MCP (Multi-Perspective Co-creation) is a framework designed for automated, structured debates among AI agents to collaboratively solve complex problems. It orchestrates a dynamic process where multiple AI "Actors"—each embodying unique, predefined roles, personalities, and expertise—engage in an iterative exchange of proposals, critiques, and refinements.

The primary purpose of Dog Fight MCP is to simulate an expert panel discussion or a "think tank" environment. By leveraging diverse AI personas, the system aims to produce well-rounded, robust, and thoroughly vetted solutions that consider multiple viewpoints. It seeks to uncover deeper insights, rigorously challenge assumptions, and explore a wider range of potential strategies than a monolithic AI approach might achieve, thereby mirroring the collaborative intelligence and creative friction of a human expert team. This methodology is particularly effective for tackling multifaceted problems where no single perspective holds all the answers.

### Key Features:

*   **Multi-Actor System:** The framework employs a team of AI agents, referred to as "Actors." Each Actor is configured with a distinct profile, including its area of expertise (e.g., "Security Engineer," "Financial Analyst"), behavioral traits (e.g., "cautious," "innovative"), and specific viewpoints or objectives. This ensures that problems are examined comprehensively from multiple relevant angles.
*   **Iterative Debate Process:** Solutions are developed and refined through multiple rounds of structured interaction. In each round, Actors may generate initial proposals, provide critiques of others' ideas, offer counter-proposals, and adapt their positions based on the ongoing discussion. This iterative cycle allows for the progressive strengthening and optimization of the final solution.
*   **Scribe Functionality:** A specialized AI agent, designated as the "Scribe," plays a crucial neutral role in the debate. The Scribe is responsible for collecting, impartially summarizing, and synthesizing the diverse opinions, arguments, and proposals generated by the Actors. It then formulates coherent draft solutions that reflect the collective intelligence of the group, often highlighting areas of emerging consensus as well as points of persistent contention.
*   **Consensus Mechanism & Voting:** To help guide the debate towards a converged outcome, Actors participate in a voting process to evaluate the consolidated drafts produced by the Scribe. This mechanism helps to identify the most widely supported ideas and can be used to determine whether a proposed solution is sufficiently agreed upon or requires further debate and refinement.
*   **LLM-Powered Intelligence:** The cognitive capabilities of both the Actors and the Scribe are powered by advanced Large Language Models (LLMs). This enables them to understand complex and nuanced problem statements, generate coherent and contextually relevant arguments, reason effectively about different proposals, and adapt their communication and strategies throughout the structured debate.

## How it Works

The Dog Fight MCP process unfolds in a series of structured steps:

1.  **Problem Definition:** The process begins with a clearly defined problem statement that the AI Actors will address.
2.  **Initial Proposals:** Each AI Actor, operating with its unique persona (e.g., "Security Engineer," "Product Manager," "UX Designer"), individually analyzes the problem and generates an initial proposal. These proposals reflect their specific expertise and biases.
3.  **Scribe Synthesis:** The "Scribe" AI collects all the initial proposals. It then synthesizes them into a single, unified draft document. This draft aims to capture the core ideas from each proposal, identify common themes, and explicitly note points of agreement as well as conflicting perspectives or disagreements among the Actors.
4.  **Voting and Reasoning:** The Scribe's unified draft is presented back to all Actors. Each Actor reviews the draft and casts a vote (e.g., AGREE or DISAGREE with the current draft as a viable solution). Crucially, along with their vote, Actors provide detailed reasoning, explaining why they support or oppose the draft and suggesting specific improvements or alternative considerations.
5.  **Iterative Refinement:** The feedback (votes and reasons) from the Actors is used to refine the solution. This can trigger further rounds of debate:
    *   Actors might revise their original proposals or generate new ones based on the Scribe's summary and the feedback from other Actors.
    *   The Scribe may produce new versions of the unified draft based on the evolving discussion.
    This iterative process continues for a predetermined number of rounds or until a predefined consensus threshold (e.g., a certain percentage of Actors agreeing with the draft) is achieved.

Throughout this process, the goal is to leverage the diverse perspectives of the Actors to explore the problem space thoroughly and collaboratively construct a solution that is more robust and comprehensive than any single Actor could produce alone.

## Project Structure

The project is organized as follows:

*   `python/server.py`: The main FastAPI server script that exposes the Dog Fight MCP tools (like `debate_alternatives`) as API endpoints.
*   `python/dogfighters/dogfight.py`: Contains the core logic for orchestrating the dogfight process, managing rounds, interactions between Actors and the Scribe, and determining consensus.
*   `python/dogfighters/actor.py`: Defines the `Actor` class, including its ability to generate proposals and vote on drafts based on its persona.
*   `python/dogfighters/scribe.py`: Defines the `Scribe` class, responsible for synthesizing proposals and creating unified drafts.
*   `python/llm/`: This directory houses LLM client implementations. For example, `anthropic_client.py` provides a client for interacting with Anthropic's Claude models. It relies on an abstract `llm_client.py` for a common interface.
*   `tools/setup-python.sh`: A shell script to help set up the Python environment and install necessary dependencies.
*   `readme.md`: This file, providing an overview and guide to the project.

## Getting Started

### Prerequisites

*   **Python 3.8+**: Ensure you have a compatible Python version installed.
*   **Anthropic API Key**: Access to Anthropic's Claude models is required. This key must be set as an environment variable named `ANTHROPIC_API_KEY`.

### Setup

1.  **Clone the Repository:**
    If you haven't already, clone the project repository to your local machine.
    ```bash
    # Example: git clone <repository_url>
    # cd <repository_directory>
    ```

2.  **Set up Python Environment:**
    Open your terminal and run the setup script located in the `tools` directory:
    ```bash
    bash tools/setup-python.sh
    ```
    This script will:
    *   Create a Python virtual environment (typically in a `.venv` directory).
    *   Activate the virtual environment.
    *   Install the required Python packages listed in `python/requirements.txt`.

    If you need to activate the virtual environment manually in a new terminal session, use:
    ```bash
    source .venv/bin/activate
    ```

3.  **Configure API Key:**
    Set your Anthropic API key as an environment variable.
    ```bash
    export ANTHROPIC_API_KEY="your_actual_api_key_here"
    ```
    Replace `"your_actual_api_key_here"` with your valid Anthropic API key. It's recommended to add this line to your shell's configuration file (e.g., `.bashrc`, `.zshrc`) for persistence across sessions.

### Running the Server

Once the setup is complete and the virtual environment is active, you can start the MCP server:

```bash
python python/server.py
```

By default, the server will run on `http://127.0.0.1:8000`. You should see output indicating that the Uvicorn server is running and ready to accept requests.

### Interacting with the Server

The server uses FastMCP, which means its tools can be called by any MCP-compatible client. For testing and exploration, you can use tools like `curl` or FastAPI's built-in interactive documentation.

*   **Interactive API Docs (Swagger UI):** Once the server is running, navigate to `http://127.0.0.1:8000/docs` in your web browser. This interface allows you to see available tools, their parameters, and execute them directly.
*   **Conceptual `curl` Example for `debate_alternatives`:**
    ```bash
    curl -X POST "http://127.0.0.1:8000/debate_alternatives" \
    -H "Content-Type: application/json" \
    -d '{
      "problem": "Should our company transition to a fully remote work model, a hybrid model, or remain office-centric post-pandemic?",
      "max_rounds": 3
    }'
    ```
    The server will respond with the Scribe's final report after the debate concludes.

## Configuration

The behavior of a dogfight can be customized primarily by modifying `python/server.py` where the `Dogfight` instance is created and its parameters are set, or by adjusting the `Dogfight` class defaults in `python/dogfighters/dogfight.py`.

Key configuration aspects include:

*   **Defining Actors and Their Personalities:**
    Actors are defined within the `debate_alternatives` function in `python/server.py`. A dictionary maps actor names to their detailed expertise and persona descriptions:
    ```python
    actors_config = {
        "Security Engineer": "Specializes in security and compliance, risk assessment, and data protection. Prefers established, secure technologies.",
        "Product Manager": "Focuses on user needs, market viability, and product strategy. Aims for innovative solutions that meet business goals.",
        "Infrastructure Engineer": "Concerned with scalability, reliability, cost-effectiveness, and maintainability of infrastructure. Prefers proven, robust solutions."
        # Add or modify Actors here
    }
    actors = [Actor(name, expertise, debug_mode=True) for name, expertise in actors_config.items()]
    ```
    You can add, remove, or modify Actors and their expertise strings to tailor the debate to different problem domains or perspectives.

*   **Setting Maximum Rounds (`max_rounds`):**
    The `max_rounds` parameter for a debate dictates the maximum number of proposal-synthesis-voting iterations. It can be set when calling the `debate_alternatives` tool (as seen in the `curl` example) or defined with a default value in the tool's signature in `python/server.py`.
    ```python
    # In server.py, within the debate_alternatives tool definition:
    # def debate_alternatives(problem: str, max_rounds: int = 3) -> str:
    #     ...
    #     dogfight = Dogfight(actors, scribe, problem, max_rounds=max_rounds, ...)
    ```

*   **Setting Consensus Threshold (`consensus_threshold`):**
    The `consensus_threshold` is a float between 0.0 and 1.0 that determines the percentage of Actors that must agree with a draft for consensus to be considered reached, potentially ending the debate early. This is typically set during the `Dogfight` instantiation.
    ```python
    # In python/dogfighters/dogfight.py, the Dogfight class constructor:
    # def __init__(self, ..., consensus_threshold: float = 0.75, ...):
    #     self.consensus_threshold = consensus_threshold
    ```
    You can modify this default in `dogfight.py` or, for more dynamic control, design it to be passed as a parameter from `server.py`.

*   **Debug Mode (`debug_mode`):**
    The `Dogfight`, `Actor`, and `Scribe` classes often include a `debug_mode` parameter (boolean). When set to `True`, it enables more verbose logging and print statements, which can be helpful for understanding the internal workings and troubleshooting. This is typically set during object instantiation:
    ```python
    # Example in server.py:
    # scribe = Scribe(debug_mode=True)
    # actors = [Actor(name, expertise, debug_mode=True) for name, expertise in actors_config.items()]
    # dogfight = Dogfight(actors, scribe, problem, debug_mode=True, ...)
    ```

Modifying these parameters allows you to control the nature, length, depth, and desired outcome of the simulated debates.

## Available Tools (via FastMCP)

The following tools are exposed by the FastMCP server defined in `python/server.py`:

*   **`hello_world(name: str = "World") -> str`**
    ```
    A simple tool that returns a greeting message.
    Useful for testing if the server is responsive.
    ```
    *   `name` (str, optional): The name to include in the greeting. Defaults to "World".
    *   Returns (str): A string like "Hello, {name} from the MCP server!".

*   **`debate_alternatives(problem: str, max_rounds: int = 3) -> str`**
    ```
    Initiates a "dogfight" debate among configured AI Actors to address the given problem.
    Actors will generate proposals, the Scribe will synthesize them, and Actors will vote
    iteratively until consensus is reached or max_rounds are completed.
    ```
    *   `problem` (str): The problem statement to be debated and solved by the AI Actors.
    *   `max_rounds` (int, optional): The maximum number of debate rounds (iterations of proposal, synthesis, and voting). Defaults to 3.
    *   Returns (str): A report from the Scribe, which includes the final synthesized proposal (or the latest draft if no consensus was reached), the voting history, and the reasons provided by each Actor for their votes.

## Demo

[![Demo](https://img.youtube.com/vi/huVsp-4QUFM/maxresdefault.jpg)](https://youtu.be/huVsp-4QUFM)
